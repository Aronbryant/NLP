{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aron\\anaconda3\\lib\\site-packages\\tqdm\\std.py:697: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import transformers as tfs\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc='pandas bar')\n",
    "from torch import nn\n",
    "import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=1)\n",
    "model_path = 'model'\n",
    "dataset_path = 'dataset'\n",
    "SUMMARY_OUTPUT_PATH = 'summary'\n",
    "PRETRAINED_BERT_ENCODER_PATH = 'pretrain'\n",
    "FINETUNED_BERT_ENCODER_PATH = os.path.join(model_path, \"finetuned_bert.bin\")\n",
    "BERT_MODEL_SAVE_PATH = model_path\n",
    "PU_MODEL_SAVE_PATH = os.path.join(model_path, \"pu_model.bin\")\n",
    "TEST_FILE_PATH = os.path.join(dataset_path, \"preprocessed_test.json\")\n",
    "SUMMARY_OUTPUT_PATH = os.path.join(SUMMARY_OUTPUT_PATH, \"submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX = INDEX = ['人物专栏', '作品分析', '情感解读', '推荐文', '攻略文', '治愈系文章', '深度事件', '物品评测', '科普知识文', '行业解读']\n",
    "MODEL_EPOCH=5\n",
    "\n",
    "\n",
    "class MyBertEncoder(nn.Module):\n",
    "    \"\"\"自定义的Bert编码器\"\"\"\n",
    "    def __init__(self, tokenizer_path, finetuned_bert_path):\n",
    "        super(MyBertEncoder, self).__init__()\n",
    "        model_class, tokenizer_class = tfs.BertModel, tfs.BertTokenizer\n",
    "        self.tokenizer = tokenizer_class.from_pretrained(tokenizer_path)\n",
    "        self.bert = torch.load(finetuned_bert_path)\n",
    "\n",
    "    def forward(self, batch_sentences):\n",
    "        batch_tokenized = self.tokenizer.batch_encode_plus(batch_sentences, add_special_tokens=True,\n",
    "                                                           max_length=512, pad_to_max_length=True)\n",
    "\n",
    "        input_ids = torch.tensor(batch_tokenized['input_ids']).cuda()\n",
    "        token_type_ids = torch.tensor(batch_tokenized['token_type_ids']).cuda()\n",
    "        attention_mask = torch.tensor(batch_tokenized['attention_mask']).cuda()\n",
    "\n",
    "        bert_output = self.bert(input_ids=input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
    "        bert_cls_hidden_state = bert_output[0][:, 0, :]\n",
    "        return bert_cls_hidden_state\n",
    "def prepare_sequence(title: str, body: str):\n",
    "    return (title, body[:256] + \"|\" + body[-256:])\n",
    "def read_test_file(input_path:str):\n",
    "    test_df = pd.read_json(input_path,orient=\"records\",lines=True)\n",
    "    \n",
    "    return test_df\n",
    "def predict_with_pu(x,idnex,pu_classifier,bert_encoder,bert_classifier_model):\n",
    "    text = prepare_sequence(x[\"title\"],x[\"body\"])\n",
    "    encoded_pos = np.array(bert_encoder([text]).tolist())\n",
    "    pu_result = pu_classifier(encoded_pos)\n",
    "    if pu_result[0] < 0:\n",
    "        predicted_label = \"其他\"\n",
    "        proba = 0.5\n",
    "    else:\n",
    "        output = bert_classifier_model([text])\n",
    "        predicted_proba = softmax(output).tolist()[0]\n",
    "        predicted_index = np.argmax(predicted_proba)\n",
    "        predicted_label = index[predicted_index]\n",
    "        \n",
    "        proba = predicted_proba[predicted_index]\n",
    "    return [predicted_label,round(prob,2)]\n",
    "def summary(test_df,output_path,pu_classifier,bert_encoder,bert_classifier_model):\n",
    "    test_df[[\"preidcted_label\",\"proba\"]] = test_df.progress_apply(\n",
    "     lambda x:pd.Series(predict_with_pu(x, INDEX, pu_classifier, bert_encoder, bert_classifier_model)), axis=1)\n",
    "    csv_data = test_df.loc[:,[\"id,predicted_label\"]]\n",
    "    csv_data.columns = [\"id\",\"predict_doctype\"]\n",
    "    csv_data.to_csv(output_path,index=0,line_terminator=\"\\r\\r\\n\")\n",
    "def joint_predictor():\n",
    "    torch.cuda.set_device(0)\n",
    "    fs = os.listdir(BERT_MODEL_SAVE_PATH)\n",
    "    gs = list()\n",
    "    for f in fs:\n",
    "        if 'model_epoch' in f:\n",
    "            gf.append(f)\n",
    "    MODEL_EPOCH = max([int(x.split('.')[0].split('model_epoch')[-1])] for x in gs)\n",
    "    model_save_path = os.path.join(BERT_MODEL_SAVE_PATH,'model_epoch{}.pkl'.format(MODEL_EPOCH))\n",
    "    test_df = read_test_file(TEST_FILE_PATH)\n",
    "    bert_classifier_model = torch.load(model_save_path)\n",
    "    bert_classifier_model = bert_classifier_model.cuda()\n",
    "    bert_classifier_model.evall()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        pu_classifier = joblib.load(PU_MODEL_SAVE_PATH)\n",
    "        bert_encpder = MyBertEncoder(PRETRAINED_BERT_ENCODER_PATH,FINETUNED_BERT_ENCODER_PATH)\n",
    "        bert_encpder.eval()\n",
    "        summary(test_df,SUMMARY_OUTPUT_PATH,pu_classifier,bert_encpder,bert_classifier_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
